{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a800c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vishn\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 158ms/step - accuracy: 0.9649 - loss: 0.0824 - val_accuracy: 1.0000 - val_loss: 7.3214e-06\n",
      "Epoch 2/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 161ms/step - accuracy: 1.0000 - loss: 7.1452e-06 - val_accuracy: 1.0000 - val_loss: 1.5146e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 1.5960e-06 - val_accuracy: 1.0000 - val_loss: 4.2006e-07\n",
      "Epoch 4/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 4.5814e-07 - val_accuracy: 1.0000 - val_loss: 1.0245e-07\n",
      "Epoch 5/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.1851e-07 - val_accuracy: 1.0000 - val_loss: 1.5646e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Load datasets\n",
    "sentiment_df = pd.read_excel(\"mental_health_datasets .xlsx\", sheet_name=\"Sentiment Analysis\")\n",
    "emotion_df = pd.read_excel(\"mental_health_datasets .xlsx\", sheet_name=\"Emotional State Classification\")\n",
    "\n",
    "# Prepare sentiment analysis data\n",
    "X_sentiment = sentiment_df[\"Text\"].values\n",
    "y_sentiment = sentiment_df[\"Sentiment\"].values\n",
    "sentiment_encoder = LabelEncoder()\n",
    "y_sentiment = sentiment_encoder.fit_transform(y_sentiment)\n",
    "\n",
    "# Prepare emotional state classification data\n",
    "X_emotion = emotion_df[\"Text\"].values\n",
    "y_emotion = emotion_df[\"Emotion\"].values\n",
    "emotion_encoder = LabelEncoder()\n",
    "y_emotion = emotion_encoder.fit_transform(y_emotion)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(np.concatenate((X_sentiment, X_emotion)))\n",
    "\n",
    "X_sentiment = tokenizer.texts_to_sequences(X_sentiment)\n",
    "X_sentiment = pad_sequences(X_sentiment, maxlen=max_len)\n",
    "\n",
    "X_emotion = tokenizer.texts_to_sequences(X_emotion)\n",
    "X_emotion = pad_sequences(X_emotion, maxlen=max_len)\n",
    "\n",
    "# Split datasets\n",
    "X_train_sent, X_test_sent, y_train_sent, y_test_sent = train_test_split(X_sentiment, y_sentiment, test_size=0.2, random_state=42)\n",
    "X_train_emot, X_test_emot, y_train_emot, y_test_emot = train_test_split(X_emotion, y_emotion, test_size=0.2, random_state=42)\n",
    "\n",
    "sentiment_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dense(3, activation=\"softmax\")  # 3 classes: Positive, Neutral, Negative\n",
    "])\n",
    "\n",
    "sentiment_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "sentiment_model.fit(X_train_sent, y_train_sent, epochs=5, validation_data=(X_test_sent, y_test_sent))\n",
    "sentiment_model.save(\"sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d247d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 65ms/step - accuracy: 0.9483 - loss: 0.1607 - val_accuracy: 1.0000 - val_loss: 4.0979e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.6649e-05 - val_accuracy: 1.0000 - val_loss: 8.1208e-06\n",
      "Epoch 3/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 7.9011e-06 - val_accuracy: 1.0000 - val_loss: 2.1655e-06\n",
      "Epoch 4/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.1188e-06 - val_accuracy: 1.0000 - val_loss: 5.9146e-07\n",
      "Epoch 5/5\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 5.9993e-07 - val_accuracy: 1.0000 - val_loss: 1.4997e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "emotion_model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dense(len(emotion_encoder.classes_), activation=\"softmax\")  # Number of emotion categories\n",
    "])\n",
    "\n",
    "emotion_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "emotion_model.fit(X_train_emot, y_train_emot, epochs=5, validation_data=(X_test_emot, y_test_emot))\n",
    "emotion_model.save(\"emotion_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bb2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
